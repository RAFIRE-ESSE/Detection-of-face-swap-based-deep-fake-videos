# RAFIRE-ESSE-Detection-of-face-swap-based-deep-fake-videos

Our problem statement is to detect the face-swap in deepfake videos. To solve this problem, we clustered multiple deep learning models to construct a superior model that can identify deepfake using videos frames and audio. In our method, we combine three different approaches they are ii. Adversarial Training  iv. Long Short-Term Memory (LSTM) Networks  ix. Hybrid Models
 
In our idea, we developed a deepfake detection model with the help of multiple sub-models. Rather than training a CNN using train images in the given datasets, where the parameters of CNN are only trained to predict the image in the training data. so, it is harder for the model developed in the way to predict new deepfake for that, so we use GAN in which a generator is used to train a discriminator to find deepfake this method the discriminator (CNN) will be trained in different parameters every single time so that there is a higher chance of prediction new deepfake. This model consists of two GAN (Generative adversarial networks) models and one RNN (Recurrent neural network) model. In the GAN model, one of the deep-face discriminators is used for predicting fabricated faces and another one for predicting fabricated voice, and the RNN model uses the result of the deep face and voice model with its frame sequence to finalize whether the video is fabricated or not. For the RNN model, LSTM is used due to the reason that the LSTM is good at remembering the time sequence so there is a pretty good chance of remembering the changes in the result in the frame sequence. 
 
Before using the model to predict the deepfakes first we need to do some preprocessing such as splitting the frames and audio from the video. Next, we need to extract faces from the frame by using the haar cascade algorithm and voice from the audio by neutralizing the noise from the audio. Then the face image should be enhanced and changed to the specified color format, which we find by analyzing different color formats to make the prediction more efficient while predicting the fabricated faces and voices in the videos. 
 
In this way, we can accurately predict which of the faces are fabricated by using deepfake models and which are not. If even the deep face model cannot able to predict the fabrication of the faces in the image. we can use the disturbances in the audio and deep-voice classifier to predict whether the fabrication is done on the audio to match the fabrication in faces and classify whether the video is fabricated are not. Due to the inclusion of RNN, we would not need to worry about the collapsed face frames in-between the frames to explain it clearly if we take a real video we can see some frames the face get into weird shapes due to the moment of the person and low frame rate in the video so sometimes the deep-face model consider it as a fake image or fabrication to avoid it we can use the LSTM to analysis the patterns in the miss structured frames to avoid wrong conclusions.

![NOISE FILTER](https://github.com/user-attachments/assets/2ced638a-df83-43af-8847-68decf4fd2b5)
